{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf8bec0",
   "metadata": {},
   "source": [
    "# Credit Card fraud detection using Deep Learning project\n",
    "# codes - Submitted By: Devran Dey Sarkar(1181700008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1697a9",
   "metadata": {},
   "source": [
    "## Importing Dependencies from various Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b52925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.utils\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4964019",
   "metadata": {},
   "source": [
    "## Importing the pre-processed training dataset from local computer storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4449e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Project Related(ML)\\project dataSet\\CreditCardNewDataSet\\Credit Card Final V1\\Training Data Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff439d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the presence of Null Values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2324e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of different classes i.e., Fraudulent and Genuine\n",
    "df['Class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the count of fraud and legitimate class in the training dataset \n",
    "df['Class'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the heatmap of the dataset ; it is used to show the dependency of each feature in providing the output \n",
    "f, ax1 = plt.subplots(figsize=(24,10))\n",
    "\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\n",
    "ax1.set_title(\"Imbalanced Correlation Matrix\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea20b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making some changes in the dataset which include removal of Time column from the training dataset\n",
    "X = df.drop(['Time', 'Class'], axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into traning and testing ; validation data is 15% and shuffling of the data in permitted\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15,shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafe79f",
   "metadata": {},
   "source": [
    "## Using Earlystopping technique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=2, mode=min,\n",
    "                                        restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b43e3",
   "metadata": {},
   "source": [
    "## Developing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ba9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the model structure for proposed model-1\n",
    "clf = Sequential([\n",
    "    Dense(units=128, kernel_initializer='uniform', input_dim=29, activation='relu'),\n",
    "    Dense(units=64, kernel_initializer='uniform', activation='relu'),                            \n",
    "    Dense(32, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(16, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(8, kernel_initializer='uniform', activation='relu'), \n",
    "    Dense(1, kernel_initializer='uniform', activation='sigmoid')\n",
    "])\n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4259d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27c78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe897df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model \n",
    "clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae225e0",
   "metadata": {},
   "source": [
    "## Training the model and validating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17862a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the epoch used is 30 and the batch size is 700 ; shuffling of the data is permitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = clf.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=30, batch_size=700 ,\n",
    "               callbacks=[earlystopping], shuffle=True, verbose = 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9eea4",
   "metadata": {},
   "source": [
    "## For visualising the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(hist.history['loss'],'r',linewidth=1.0)\n",
    "plt.plot(hist.history['val_loss'],'b',linewidth=1.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Loss',fontsize=12)\n",
    "plt.title('Loss Curves',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(hist.history['accuracy'],'r',linewidth=1.0)\n",
    "plt.plot(hist.history['val_accuracy'],'b',linewidth=1.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Accuracy',fontsize=12)\n",
    "plt.title('Accuracy Curves',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f18c57",
   "metadata": {},
   "source": [
    "## For testing Purpose fetching the pre-processed testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5faeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file is stored in local computer storage\n",
    "df_test = pd.read_csv(r\"D:\\Project Related(ML)\\project dataSet\\CreditCardNewDataSet\\Credit Card Final V1\\Testing Data Set Additional.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269e4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the count of fraud and legitimate class in the testing dataset\n",
    "df_test[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c73d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(['Time', 'Class'], axis=1)\n",
    "y_test = df_test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541da2cb",
   "metadata": {},
   "source": [
    "## Testing the model and visualising the result using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b04d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test) > 0.5\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "labels = ['Legitimate', 'Fraudulent']\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='magma', \n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('Actual label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da6466",
   "metadata": {},
   "source": [
    "## Showing the performance using various result parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Accuracy = \",accuracy_score(y_test, y_pred.round())*100)\n",
    "print(\"Precision Score\",precision_score(y_test, y_pred.round())*100)\n",
    "print(\"recall value = \",recall_score(y_test, y_pred.round())*100)\n",
    "print(\"f1 score = \",f1_score(y_test, y_pred.round())*100)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)*100\n",
    "print(\" MCC value = \",mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e747fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
